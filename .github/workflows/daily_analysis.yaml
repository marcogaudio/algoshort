name: Daily Italian Stock Analysis

on:
  # Run daily at 18:00 UTC (19:00 CET / 20:00 CEST - after market close)
  schedule:
    - cron: '0 18 * * 1-5'  # Monday to Friday at 18:00 UTC

  # Allow manual trigger
  workflow_dispatch:
    inputs:
      max_tickers:
        description: 'Maximum number of tickers to process (0 = all)'
        required: false
        default: '0'
      single_ticker:
        description: 'Process only this ticker (leave empty for all)'
        required: false
        default: ''

jobs:
  generate-notebooks:
    runs-on: ubuntu-latest
    timeout-minutes: 120  # 2 hours max for all tickers

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install poetry
          poetry config virtualenvs.create false
          poetry install --no-interaction
          pip install papermill jupyter nbconvert

      - name: Create output directories
        run: |
          mkdir -p notebooks
          mkdir -p results
          mkdir -p cache

      - name: Generate and execute notebooks
        run: |
          # Determine arguments based on workflow inputs
          ARGS=""

          if [ "${{ github.event.inputs.single_ticker }}" != "" ]; then
            ARGS="--ticker ${{ github.event.inputs.single_ticker }}"
          elif [ "${{ github.event.inputs.max_tickers }}" != "0" ] && [ "${{ github.event.inputs.max_tickers }}" != "" ]; then
            ARGS="--max-tickers ${{ github.event.inputs.max_tickers }}"
          fi

          python generate_notebooks.py $ARGS

      - name: Generate consolidated report
        run: |
          python -c "
          import pandas as pd
          import glob
          import os
          from datetime import datetime

          # Consolidate equity results
          equity_files = glob.glob('results/*_equity.csv')
          if equity_files:
              dfs = []
              for f in equity_files:
                  ticker = os.path.basename(f).replace('_equity.csv', '').replace('_', '.')
                  df = pd.read_csv(f)
                  df['Ticker'] = ticker
                  dfs.append(df)

              combined = pd.concat(dfs, ignore_index=True)
              combined = combined.sort_values(['Ticker', 'Return %'], ascending=[True, False])
              combined.to_csv('results/consolidated_equity.csv', index=False)
              print(f'Consolidated {len(equity_files)} equity files')

          # Consolidate signal results
          signal_files = glob.glob('results/*_signals.csv')
          if signal_files:
              dfs = [pd.read_csv(f) for f in signal_files]
              combined = pd.concat(dfs, ignore_index=True)
              combined.to_csv('results/consolidated_signals.csv', index=False)
              print(f'Consolidated {len(signal_files)} signal files')

          # Create summary
          with open('results/summary.txt', 'w') as f:
              f.write(f'Italian Stock Analysis Summary\\n')
              f.write(f'Generated: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}\\n')
              f.write(f'Tickers processed: {len(equity_files)}\\n')
          "

      - name: Commit and push results
        run: |
          git config --local user.email "actions@github.com"
          git config --local user.name "GitHub Actions"

          # Add all generated files
          git add notebooks/*.ipynb || true
          git add results/*.csv || true
          git add results/*.txt || true
          git add cache/*.parquet || true

          # Create commit with date
          DATE=$(date +%Y-%m-%d)
          git commit -m "Daily analysis: $DATE" || echo "No changes to commit"

          # Push changes
          git push origin main || echo "No changes to push"

      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: analysis-results-${{ github.run_number }}
          path: |
            notebooks/
            results/
          retention-days: 30

  # Optional: Send notification on failure
  notify-on-failure:
    needs: generate-notebooks
    runs-on: ubuntu-latest
    if: failure()
    steps:
      - name: Create failure summary
        run: |
          echo "## Daily Analysis Failed" >> $GITHUB_STEP_SUMMARY
          echo "The daily Italian stock analysis workflow failed." >> $GITHUB_STEP_SUMMARY
          echo "Please check the workflow logs for details." >> $GITHUB_STEP_SUMMARY
